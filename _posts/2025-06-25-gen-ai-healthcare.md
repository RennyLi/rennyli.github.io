---
layout: post
title: Reflections on Generative AI in Healthcare
date: 2025-06-25 21:30:00 +0800
description: Thoughts on Stanford’s AI in Healthcare series and the complex promise of human-centered intelligence in medical applications.
tags: AI healthcare human-centered
categories: learning-journal
giscus_comments: false
related_posts: false
toc:
  sidebar: left
---

> *“It’s more like a river than a lake.”*  

Today I watched the first episode of Stanford Online’s new seminar series on AI in Healthcare. The session featured a thought-provoking discussion among multiple speakers, including Troy Tazbaz, former head of digital health at the FDA, who joined as a guest speaker. The conversation left me reflecting on the complex — and often contradictory — reality of generative AI in medicine.

As someone who has long been fascinated by the promise of AI in psychological support, patient education, and human-machine interaction, I came into this video expecting technical insights. Instead, what I found was a deeper conversation: about trust, responsibility, and the human dimensions that technology can’t (and shouldn’t) replace.

## What I Used to Think: The Promise of AI in Healthcare

Before watching this video, I already believed that generative AI could play a major role in healthcare. For example, I had read research on AI chatbots used in mental health scenarios — offering patients conversational comfort and basic coping guidance. I also saw firsthand how my father, who is currently undergoing chemotherapy, uses tools like DeepSeek or ChatGPT to understand complex medical reports, drug instructions, and treatment options. These tools help demystify medical jargon in ways that feel empowering.

To me, this is what makes healthcare such a meaningful domain for AI — because it touches every life.

Still, I had concerns. ChatGPT and similar tools are not always reliable. They hallucinate. They make things up. I wasn’t sure how we could reconcile this unreliability with the life-and-death nature of medicine.

## Why Can’t Doctors Use It Freely?

The host Justin Norden raised a great question in the slides: why are so many healthcare professionals restricted from using AI tools? He called it a “weird phenomenon,” and I agree. It seems paradoxical — we have powerful tools, but the people who might benefit most can’t touch them.

In my view, there are two main reasons for this:

**First, the underlying knowledge base of these models hasn’t been fully validated.** No hospital wants to base treatment decisions on potentially flawed data.

**Second, there’s no system-wide training in place.** Most doctors aren’t trained in how to use or even critically evaluate generative AI tools. Without that structure, adoption remains slow.

So despite all the excitement, practical deployment lags far behind.

## Ferrari in Traffic? Where Gen AI Helps — and Where It Can’t

> *“You could put a Ferrari in rush hour traffic on the 101… but would it get you there faster?”*
> *— Troy Tazbaz*

This analogy hit home. AI is powerful, yes — but without the right environment, it doesn’t shine.

Where AI **does** shine, I believe, is in **information retrieval and explanation**. It never forgets. It has an endless memory and can access a vast array of medical knowledge in seconds. In that sense, it might even outperform a human in helping patients understand their diagnosis, medications, or follow-up procedures.

It also has psychological advantages. In mental health support, some people may feel more comfortable opening up to a bot than to a real human. AI can be tireless, available 24/7, and free from human judgment.

But no matter how good AI gets, **there are things it can’t do.** It doesn’t have the warmth of a human being. It doesn’t touch your shoulder and tell you everything’s going to be okay. It doesn’t perform surgery — at least, not yet. And when it comes to decisions where life is at stake, we still want to look into another person’s eyes.

Maybe it’s because AI is still a tool. And when it really matters, we trust humans more.

## Toward Human-Centered Intelligence

If generative AI is a river — constantly changing, constantly moving — how do we safely navigate it?

I believe the future lies in **human-centered intelligence** — where people remain at the center of the loop. In the new HCI (Human-Computer Interaction), it’s not about replacing humans, but augmenting them. Human + AI, learning and correcting one another iteratively.

One potential path forward is to **build structured pipelines**. For example, an AI could generate a medical recommendation, which is then reviewed by a trained expert before reaching the patient. Yes, it adds human cost. But for now, it may be the most trustworthy way.

In this fast-moving era, we don’t need to rush to full automation. What we need is thoughtful integration — balancing innovation with responsibility, and remembering always that the ultimate goal is not to impress, but to heal.

Let the river flow — but let humans steer the boat.